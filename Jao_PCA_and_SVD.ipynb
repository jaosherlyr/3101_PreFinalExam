{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PCA and SVD [Pre Final Exam]\n",
    "**Name: Sherly R. Jao**\n",
    "**Course and Year: BSCS-3**\n",
    "**Subj: CS-3101N**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table:\n",
      "Num | Country |    X1 |   X2 |    X3 |   X4\n",
      " 10 | Hungary |     m |    m |     m |    m\n",
      " 22 |  Poland | -0.03 | 0.58 | -0.03 | 0.85\n",
      " 27 | Hungary |     m |    m |     m |    m\n",
      " 73 |  Poland |  0.01 | 0.71 |  0.08 | 1.13\n",
      " 74 |  Poland | -0.13 |  1.1 | -0.43 | 0.27\n",
      "\n",
      "Centered Data:\n",
      "[0.019999999999999997, -0.21666666666666679, 0.09666666666666668, 0.09999999999999998]\n",
      "[0.06, -0.08666666666666678, 0.20666666666666667, 0.3799999999999999]\n",
      "[-0.08000000000000002, 0.30333333333333334, -0.30333333333333334, -0.48]\n",
      "\n",
      "Mean Values:\n",
      "-0.049999999999999996\n",
      "0.7966666666666667\n",
      "-0.12666666666666668\n",
      "0.75\n",
      "\n",
      "Covariance Matrix:\n",
      "[0.0052000000000000015, -0.016900000000000005, 0.019300000000000005, 0.031599999999999996]\n",
      "[-0.016900000000000005, 0.07323333333333337, -0.06543333333333336, -0.10010000000000002]\n",
      "[0.019300000000000005, -0.06543333333333336, 0.07203333333333334, 0.1169]\n",
      "[0.031599999999999996, -0.10010000000000002, 0.1169, 0.19239999999999996]\n",
      "\n",
      "Eigenvalues: [0.0052000000000000015, 0.07323333333333337, 0.07203333333333334, 0.19239999999999996]\n",
      "Eigenvectors: [[1.0, 0.0, 0.0, 0.0], [-1.166530504932556, 1.0, 0.0, 0.0], [0.3888746796635583, -0.6707348283826108, 1.0, 0.0], [-1.9277564657126132, -1.5129659063898582, -1.851362554036261, 1.0]]\n",
      "\n",
      "Sorted Eigenvalues:\n",
      "[0.19239999999999996, 0.07323333333333337, 0.07203333333333334, 0.0052000000000000015]\n",
      "\n",
      "Sorted Eigenvectors:\n",
      "[-1.9277564657126132, -1.5129659063898582, -1.851362554036261, 1.0]\n",
      "[-1.166530504932556, 1.0, 0.0, 0.0]\n",
      "[0.3888746796635583, -0.6707348283826108, 1.0, 0.0]\n",
      "[1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Selected Eigenvectors Matrix:\n",
      "[-1.9277564657126132, -1.5129659063898582, -1.851362554036261, 1.0]\n",
      "[-1.166530504932556, 1.0, 0.0, 0.0]\n",
      "\n",
      "Result Matrix:\n",
      "[0.21419314675446838, -0.24692598479446395, -0.037027251080725215, 0.019999999999999997]\n",
      "[-0.014566077515268464, -0.17744462105005826, -0.11108175324217566, 0.06]\n",
      "[-0.1996270692391996, 0.424370605844522, 0.14810900432290092, -0.08000000000000002]\n"
     ]
    }
   ],
   "source": [
    "# Parsing the file\n",
    "def parse_arff(file_path):\n",
    "    attributes = []\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        in_data_section = False\n",
    "\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line.startswith('%'):\n",
    "                continue\n",
    "\n",
    "            if in_data_section:\n",
    "                data.append(line.split(','))\n",
    "            else:\n",
    "                if line.lower().startswith('@attribute'):\n",
    "                    attribute_name = line.split()[1]\n",
    "                    attributes.append(attribute_name)\n",
    "                elif line.lower().startswith('@data'):\n",
    "                    in_data_section = True\n",
    "\n",
    "    return attributes, data\n",
    "\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    return sum(x * y for x, y in zip(v1, v2))\n",
    "\n",
    "def vector_norm(v):\n",
    "    return sum(x**2 for x in v)**0.5\n",
    "\n",
    "def matrix_multiplication(matrix1, matrix2):\n",
    "    result = []\n",
    "    for i in range(len(matrix1)):\n",
    "        row = []\n",
    "        for j in range(len(matrix2[0])):\n",
    "            element = sum(matrix1[i][k] * matrix2[k][j] for k in range(len(matrix2)))\n",
    "            row.append(element)\n",
    "        result.append(row)\n",
    "    return result\n",
    "\n",
    "def qr_algorithm(matrix, num_iterations=100):\n",
    "    n = len(matrix)\n",
    "    eigenvalues = [matrix[i][i] for i in range(n)]\n",
    "    eigenvectors = [[1.0 if i == j else 0.0 for j in range(n)] for i in range(n)]\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # QR decomposition\n",
    "        q, r = qr_decomposition(matrix)\n",
    "\n",
    "        # Update the matrix\n",
    "        matrix = matrix_multiplication(r, q)\n",
    "\n",
    "        # Update eigenvectors\n",
    "        eigenvectors = matrix_multiplication(eigenvectors, q)\n",
    "\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def qr_decomposition(matrix):\n",
    "    n = len(matrix)\n",
    "    q = [[0.0] * n for _ in range(n)]\n",
    "    r = [[0.0] * n for _ in range(n)]\n",
    "\n",
    "    for j in range(n):\n",
    "        v = [matrix[i][j] for i in range(j, n)]\n",
    "        norm_v = vector_norm(v)\n",
    "        q[j][j] = 1.0\n",
    "        for i in range(j + 1, n):\n",
    "            q[i][j] = v[i - j] / norm_v\n",
    "\n",
    "        for i in range(j, n):\n",
    "            for k in range(j, n):\n",
    "                r[i][k] = matrix[i][k] - 2 * q[i][j] * dot_product(q[j], matrix[i])\n",
    "\n",
    "    return q, r\n",
    "\n",
    "arff_file_path = '2020.arff'\n",
    "attributes, data = parse_arff(arff_file_path)\n",
    "\n",
    "selected_eigenvectors = []\n",
    "num_selected_eigenvectors = 2\n",
    "\n",
    "# Limit to a small dataset for testing\n",
    "attributes = attributes[:6]\n",
    "data = [row[:6] for row in data[:5]]\n",
    "\n",
    "header = \" | \".join(attributes)\n",
    "max_widths = [len(attribute) for attribute in attributes]\n",
    "for row in data:\n",
    "    for i, value in enumerate(row):\n",
    "        max_widths[i] = max(max_widths[i], len(value))\n",
    "\n",
    "numerical_data = [\n",
    "    [float(value) if value.lower() != 'm' else None for value in row[2:]]\n",
    "    for row in data\n",
    "]\n",
    "\n",
    "numerical_data = [row for row in numerical_data if all(value is not None for value in row)]\n",
    "\n",
    "mean_values = [\n",
    "    sum(filter(None, col)) / len(list(filter(None, col))) if numerical_data else None\n",
    "    for col in zip(*numerical_data)\n",
    "]\n",
    "\n",
    "centered_data = [\n",
    "    [(col - mean) if col is not None else None for col, mean in zip(row, mean_values)]\n",
    "    for row in numerical_data\n",
    "]\n",
    "\n",
    "covariance_matrix = [[0] * len(mean_values) for _ in range(len(mean_values))]\n",
    "\n",
    "for i in range(len(mean_values)):\n",
    "    for j in range(len(mean_values)):\n",
    "        for k in range(len(centered_data)):\n",
    "            covariance_matrix[i][j] += centered_data[k][i] * centered_data[k][j]\n",
    "\n",
    "covariance_matrix = [[elem / (len(centered_data) - 1) for elem in row] for row in covariance_matrix]\n",
    "\n",
    "eigenvalues, eigenvectors = qr_algorithm(covariance_matrix)\n",
    "\n",
    "sorted_indices = list(range(len(eigenvalues)))\n",
    "sorted_indices = sorted(sorted_indices, key=lambda i: eigenvalues[i], reverse=True)\n",
    "sorted_eigenvalues = [eigenvalues[i] for i in sorted_indices]\n",
    "sorted_eigenvectors = [eigenvectors[i][:] for i in sorted_indices]\n",
    "\n",
    "for i in range(num_selected_eigenvectors):\n",
    "    selected_eigenvectors.append(sorted_eigenvectors[i])\n",
    "\n",
    "result_matrix = matrix_multiplication(centered_data, selected_eigenvectors)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nTable:\")\n",
    "header_str = \" | \".join(f\"{attr:>{width}}\" for attr, width in zip(attributes, max_widths))\n",
    "print(f\"{header_str}\")\n",
    "\n",
    "for row in data:\n",
    "    row_str = \" | \".join(f\"{value:>{width}}\" for value, width in zip(row, max_widths))\n",
    "    print(row_str)\n",
    "\n",
    "print(\"\\nCentered Data:\")\n",
    "for row in centered_data:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nMean Values:\")\n",
    "for mean in mean_values:\n",
    "    print(mean)\n",
    "\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "for matrix in covariance_matrix:\n",
    "    print(matrix)\n",
    "\n",
    "print(\"\\nEigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\", eigenvectors)\n",
    "\n",
    "print(\"\\nSorted Eigenvalues:\")\n",
    "print(sorted_eigenvalues)\n",
    "\n",
    "print(\"\\nSorted Eigenvectors:\")\n",
    "for row in sorted_eigenvectors:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nSelected Eigenvectors Matrix:\")\n",
    "for row in selected_eigenvectors:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nResult Matrix:\")\n",
    "for row in result_matrix:\n",
    "    print(row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**What is similar or dissimilar between with or without the use of libraries?**\n",
    "\n",
    "The disparity in results between implementing the calculations with and without libraries is substantial. Without utilizing libraries, the process becomes notably more challenging and time-consuming, as each step must be individually computed. This results in a considerably longer runtime, particularly when dealing with large datasets. The absence of optimization through libraries not only makes the calculations cumbersome but also significantly burdens the computational resources, causing considerable lag on my laptop. To mitigate this, I've restricted the dataset for testing to a smaller subset, preventing potential overload and ensuring a more manageable execution.\n",
    "\n",
    "Variations in results can occur due to the precision of decimal points in computations. The inherent differences in how numerical calculations are handled by different libraries or methods may lead to slight discrepancies in the final output. These variations can be exacerbated when performing manual calculations without the optimization provided by specialized libraries. It's common to encounter such nuances in numerical precision, and it's often a trade-off between computational efficiency and exactness."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
